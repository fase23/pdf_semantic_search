{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page number: 0\n",
      "\t number of words: 557\n",
      "page number: 1\n",
      "\t number of words: 110\n",
      "page number: 2\n",
      "\t number of words: 453\n",
      "page number: 3\n",
      "\t number of words: 526\n",
      "page number: 4\n",
      "\t number of words: 309\n",
      "page number: 5\n",
      "\t number of words: 419\n",
      "page number: 6\n",
      "\t number of words: 613\n",
      "page number: 7\n",
      "\t number of words: 277\n",
      "page number: 8\n",
      "\t number of words: 757\n",
      "page number: 9\n",
      "\t number of words: 1064\n",
      "page number: 10\n",
      "\t number of words: 1711\n",
      "page number: 11\n",
      "\t number of words: 1502\n",
      "page number: 12\n",
      "\t number of words: 387\n",
      "\n",
      "average number of words per page: 668.0769230769231\n",
      "will be supplied upon request.  \n",
      "Differing Levels of Service provided by Global Investment Research:  The level and types of services provided to you by the Global Investment  \n",
      "Research division of GS may vary as compared to that provided to internal and other external clients of GS, depending on variou s factors including your  \n",
      "individual preferences as to the frequency and manner of receiving communication, your risk proﬁle and investment focus and per spective (e.g.,  \n",
      "marketwide, sector speciﬁc, long term, short term), the size and scope of your overall client relationship with GS, and legal a\n"
     ]
    }
   ],
   "source": [
    "# understand statistics (average number of words per page) + establish nuber of paragraphs per page\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "# Open the PDF file\n",
    "with open('data/sample1.pdf', 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    \n",
    "    # Extract text from all pages\n",
    "    tot_n_words = 0\n",
    "    for page_num in range(len(reader.pages)):\n",
    "        print(f'page number: {str(page_num)}')\n",
    "        page = reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        words = text.split(' ')\n",
    "        number_of_words = len(words)\n",
    "        print(f'\\t number of words: {number_of_words}')\n",
    "        tot_n_words += number_of_words\n",
    "    mean_w_per_page = tot_n_words/len(reader.pages)\n",
    "    print(f'\\naverage number of words per page: {mean_w_per_page}')\n",
    "    print(' '.join(words[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'that',\n",
       " 'provided',\n",
       " 'to',\n",
       " 'internal',\n",
       " 'and',\n",
       " 'other',\n",
       " 'external',\n",
       " 'clients',\n",
       " 'of',\n",
       " 'GS,',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'variou',\n",
       " 's',\n",
       " 'factors']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Differing Levels of Service provided by Global Investment Research:  The level and types of services provided to you by the Global Investment  \n",
    "Research division of GS may vary as compared to that provided to internal and other external clients of GS, depending on variou s factors\"\"\"\n",
    "words = text.split()\n",
    "words[30:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total len: 28\n",
      "0 100\n",
      "Paragraph 1: (25 words)\n",
      "Differing Levels of Service provided by Global Investment Research:  The level and types of services provided to you by the Global Investment  \n",
      "Research division of \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# divide text every 100 token\n",
    "\n",
    "def split_text_into_paragraphs(text, paragraph_size=100):\n",
    "    # Split the text into words\n",
    "    words = text.split(' ')\n",
    "    print('total len: ' + str(len(words)))\n",
    "    paragraphs = []\n",
    "    # Create paragraphs with the specified number of words\n",
    "    for i in range(0, len(words), paragraph_size):\n",
    "        print(i,i+paragraph_size)\n",
    "        paragraph = ' '.join(words[i:i + paragraph_size])\n",
    "        paragraphs.append(paragraph)\n",
    "    # merge the last paragraph if too short\n",
    "    merge_threshold = paragraph_size//2\n",
    "    if len(paragraphs) > 1 and len(paragraphs[-1].split()) < merge_threshold:\n",
    "        additional_part = paragraphs.pop()\n",
    "        paragraphs[-1] += ' ' + additional_part\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "text = \"\"\"Differing Levels of Service provided by Global Investment Research:  The level and types of services provided to you by the Global Investment  \n",
    "Research division of \"\"\"\n",
    "paragraphs = split_text_into_paragraphs(text)\n",
    "\n",
    "# Print paragraphs\n",
    "for i, paragraph in enumerate(paragraphs):\n",
    "    print(f\"Paragraph {i+1}: ({len(paragraph.split())} words)\\n{paragraph}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\prove varie\\self_made_semantic_search\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tsample0.pdf\n",
      "\tsample1.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>page</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.522988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>9</td>\n",
       "      <td>0.363853</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>0.345380</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>0.342688</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336091</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>0.311732</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>0.310567</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>0.303113</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>11</td>\n",
       "      <td>0.270189</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>12</td>\n",
       "      <td>0.248495</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample0.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>0.218584</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>0.208772</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>13</td>\n",
       "      <td>0.192139</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sample0.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>0.184770</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sample1.pdf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.182922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sample0.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>0.177380</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sample0.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sample0.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sample0.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138841</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sample0.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>0.136247</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sample0.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.115817</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  page  similarity_score  rank\n",
       "0   sample1.pdf     5          0.522988     1\n",
       "1   sample1.pdf     9          0.363853     2\n",
       "2   sample1.pdf     6          0.345380     3\n",
       "3   sample1.pdf     3          0.342688     4\n",
       "4   sample1.pdf     1          0.336091     5\n",
       "5   sample1.pdf     7          0.311732     6\n",
       "6   sample1.pdf     2          0.310567     7\n",
       "7   sample1.pdf     8          0.303113     8\n",
       "8   sample1.pdf    11          0.270189     9\n",
       "9   sample1.pdf    12          0.248495    10\n",
       "10  sample0.pdf     8          0.218584    11\n",
       "11  sample1.pdf     4          0.208772    12\n",
       "12  sample1.pdf    13          0.192139    13\n",
       "13  sample0.pdf     6          0.184770    14\n",
       "14  sample1.pdf    10          0.182922    15\n",
       "15  sample0.pdf     7          0.177380    16\n",
       "16  sample0.pdf     4          0.147453    17\n",
       "17  sample0.pdf     1          0.140018    18\n",
       "18  sample0.pdf     2          0.138841    19\n",
       "19  sample0.pdf     3          0.136247    20\n",
       "20  sample0.pdf     5          0.115817    21"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def split_text_into_paragraphs(text, paragraph_size=100):\n",
    "    # Split the text into words\n",
    "    words = text.split(' ')\n",
    "    paragraphs = []\n",
    "    # Create paragraphs with the specified number of words\n",
    "    for i in range(0, len(words), paragraph_size):\n",
    "        paragraph = ' '.join(words[i:i + paragraph_size])\n",
    "        paragraphs.append(paragraph)\n",
    "    # merge the last paragraph if too short\n",
    "    merge_threshold = paragraph_size//2\n",
    "    if len(paragraphs) > 1 and len(paragraphs[-1].split()) < merge_threshold:\n",
    "        additional_part = paragraphs.pop()\n",
    "        paragraphs[-1] += ' ' + additional_part\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "df = pd.DataFrame(columns=['file_name', 'page', 'text', 'embedding'])\n",
    "# list all .pdf in the directory (relative paths)\n",
    "files = glob.glob('data/*.pdf')\n",
    "for file in files:\n",
    "    file_name = os.path.basename(file)\n",
    "    print('\\t'+file_name)\n",
    "    # read pdf and populate the df\n",
    "    with open(file, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            paragraphs = split_text_into_paragraphs(text)\n",
    "            for par in paragraphs:\n",
    "                emb_text = model.encode(par)\n",
    "                df.loc[len(df)] = [file_name, page_num+1, par, emb_text]\n",
    "\n",
    "#pd.options.display.max_rows = None\n",
    "#display(df)\n",
    "\n",
    "# user query\n",
    "query = 'How americans are going to manage aluminium resources if russia attack ucraine'\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "# Compute the cosine similarity\n",
    "embeddings_matrix = np.vstack(df['embedding'].values) # convertion to a NumPy array for better efficiency\n",
    "similarities = model.similarity(query_embedding, embeddings_matrix)[0]\n",
    "\n",
    "# nicely print the search results\n",
    "df['similarity_score'] = similarities\n",
    "\n",
    "# row number over ordered partition\n",
    "df = df.sort_values(['file_name', 'page', 'similarity_score'], ascending=[True, True, False])  # Sort by partition column and then by value within each partition\n",
    "df['row_number'] = df.groupby(['file_name', 'page']).cumcount()\n",
    "\n",
    "# Keep only rows where row_number <= 2\n",
    "df = df[df['row_number'] <= 2]\n",
    "\n",
    "# Calculate the average 'value' for each category\n",
    "df_agg = df.groupby(['file_name', 'page'])['similarity_score'].mean().reset_index()\n",
    "df_agg = df_agg.sort_values(by='similarity_score', ascending=False).reset_index(drop=True)\n",
    "df_agg['rank'] = range(1, len(df_agg)+1)\n",
    "\n",
    "df_agg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
