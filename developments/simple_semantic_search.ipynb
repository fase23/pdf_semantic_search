{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\prove varie\\self_made_semantic_search\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Sentence: I love going to concerts and listen heavy metal, Similarity Score: 0.43723562359809875\n",
      "Sentence: I'm a very loving person, I like being outside in nature, Similarity Score: 0.21079416573047638\n",
      "Sentence: I read a lot of novels about historical facts, Similarity Score: -0.019446641206741333\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer  #util\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define your list of sentences and the text string\n",
    "sentences = [\"I'm a very loving person, I like being outside in nature\", \n",
    "             \"I love going to concerts and listen heavy metal\", \n",
    "             \"I read a lot of novels about historical facts\"]\n",
    "text_string = \"I am looking for a musician\"\n",
    "\n",
    "# Embed the list of sentences and the text string\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "#print(len(sentence_embeddings))\n",
    "text_embedding = model.encode(text_string)\n",
    "\n",
    "# Compute the cosine similarity between the text string and each sentence\n",
    "# similarities = util.cos_sim(text_embedding, sentence_embeddings)[0] #other option\n",
    "similarities = model.similarity(text_embedding, sentence_embeddings)[0]\n",
    "\n",
    "# Combine the sentences and their similarity scores, then sort by similarity score\n",
    "sentence_similarity_pairs = sorted(zip(sentences, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sentences ordered by similarity score\n",
    "for sentence, similarity in sentence_similarity_pairs:\n",
    "    print(f\"Sentence: {sentence}, Similarity Score: {similarity.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: being rich  (0.6050859689712524)\n",
      "2: having a good friend  (0.5069534778594971)\n",
      "3: being married  (0.5049541592597961)\n",
      "4: having a friend  (0.4569752514362335)\n",
      "5: having a nice car  (0.4474433362483978)\n",
      "6: having children  (0.44573670625686646)\n",
      "7: having a girlfriend  (0.4088504910469055)\n",
      "8: having a dog  (0.39964723587036133)\n",
      "9: being famous  (0.3978121280670166)\n",
      "10: having free time  (0.3967936635017395)\n",
      "11: having a cat  (0.3869970738887787)\n"
     ]
    }
   ],
   "source": [
    "# inputs\n",
    "sentences = [\"having a cat\", \n",
    "             \"having a dog\", \n",
    "             \"having a nice car\",\n",
    "             \"being famous\",\n",
    "             \"being rich\",\n",
    "             \"having a friend\",\n",
    "             \"having a good friend\",\n",
    "             \"having a girlfriend\",\n",
    "             \"being married\",\n",
    "             \"having children\",\n",
    "             \"having free time\"]\n",
    "\n",
    "text_string = \"happiness\"\n",
    "\n",
    "# elaboration\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "text_embedding = model.encode(text_string)\n",
    "similarities = model.similarity(text_embedding, sentence_embeddings)[0]\n",
    "sentence_similarity_pairs = sorted(zip(sentences, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# output\n",
    "for i in range(len(sentence_similarity_pairs)):\n",
    "    print(f\"{i+1}: {sentence_similarity_pairs[i][0]}  ({sentence_similarity_pairs[i][1]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
